{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW_pmSUB4W_f"
   },
   "source": [
    "# Big Data Examination\n",
    "# Roll No. - DS5B-2121\n",
    "## Question 1\n",
    "\n",
    "Considering left as dependent variable in HR dataset, split the dataset according to your last digit of roll no. (Example: if your roll no is ending with 0, the ratio will be 70, 30; if your roll no is ending with 1, the ratio will be 71, 29; if your roll no is ending with 2, the ratio will be 72, 28; if your roll no is ending with 3, the ratio will be 73, 27 etc.). Determine the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMQssDS3F_oJ"
   },
   "source": [
    "### Importing Pyspark Library\n",
    "It is an interface for Apache Spark in Python that allows us to write Spark applications using Python APIs, but also provides the PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YF9ed8CC4aT2",
    "outputId": "7d8f3413-b442-44a1-b88f-7e1de23b3cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 29 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 42.5 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=8b46831582fe33020b51646e24a86fc72a74a84b94240776aece0e2d97207751\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tqHqErkHrn2"
   },
   "source": [
    "## Importing Library, Creating Session and Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPPfbSiA5EkF"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "session = SparkSession.builder.appName(\"HR_comma_Dataset\").getOrCreate()\n",
    "data = session.read.csv(\"HR comma.csv\", header = True, inferSchema = True)\n",
    "#we reassign value of __name__ (inbuilt variable) to \"__main__\" and main is used as entry point in many languages like C++ and Java,\n",
    "# else the value of name might be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LtF89lX5_L_",
    "outputId": "84aaaf1a-ecce-410a-b9e8-911dfd24d3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|sales|salary|\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "|              0.38|           0.53|             2|                 157|                 3|            0|   1|                    0|sales|   low|\n",
      "|               0.8|           0.86|             5|                 262|                 6|            0|   1|                    0|sales|medium|\n",
      "|              0.11|           0.88|             7|                 272|                 4|            0|   1|                    0|sales|medium|\n",
      "|              0.72|           0.87|             5|                 223|                 5|            0|   1|                    0|sales|   low|\n",
      "|              0.37|           0.52|             2|                 159|                 3|            0|   1|                    0|sales|   low|\n",
      "|              0.41|            0.5|             2|                 153|                 3|            0|   1|                    0|sales|   low|\n",
      "|               0.1|           0.77|             6|                 247|                 4|            0|   1|                    0|sales|   low|\n",
      "|              0.92|           0.85|             5|                 259|                 5|            0|   1|                    0|sales|   low|\n",
      "|              0.89|            1.0|             5|                 224|                 5|            0|   1|                    0|sales|   low|\n",
      "|              0.42|           0.53|             2|                 142|                 3|            0|   1|                    0|sales|   low|\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ4UgLubMIjv"
   },
   "source": [
    "## Check Null Values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muteJc0jMIEn",
    "outputId": "7a632b15-65b5-4bc5-c1f1-34d32fa441c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|sales|salary|\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "|                 0|              0|             0|                   0|                 0|            0|   0|                    0|    0|     0|\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IK3xNpyiMdCt"
   },
   "source": [
    "## There are no null values in the Dataset so we will move to Exploratory Data ANalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-uBGJN1IDSQ"
   },
   "source": [
    "### SHowing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbAZQykL6kQo",
    "outputId": "33dfe1e7-97b5-4c75-eb08-b56bfbb09da4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['satisfaction_level',\n",
       " 'last_evaluation',\n",
       " 'number_project',\n",
       " 'average_montly_hours',\n",
       " 'time_spend_company',\n",
       " 'Work_accident',\n",
       " 'left',\n",
       " 'promotion_last_5years',\n",
       " 'sales',\n",
       " 'salary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V421YZgIMnm-",
    "outputId": "fe9e1f80-a752-4d2f-f2b8-ff3fcea4fa18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- satisfaction_level: double (nullable = true)\n",
      " |-- last_evaluation: double (nullable = true)\n",
      " |-- number_project: integer (nullable = true)\n",
      " |-- average_montly_hours: integer (nullable = true)\n",
      " |-- time_spend_company: integer (nullable = true)\n",
      " |-- Work_accident: integer (nullable = true)\n",
      " |-- left: integer (nullable = true)\n",
      " |-- promotion_last_5years: integer (nullable = true)\n",
      " |-- sales: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sdz2c4YqIGkk"
   },
   "source": [
    "## Importing Vector Assembler, String Indexer and One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eYoSB9t6nfg"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "# It is use for mapping a string columm to a index column that will be treated as a categorical column by spark.\n",
    "str_idx = StringIndexer(inputCols = ['sales','salary'], outputCols = [\"newsales\", \"newsalary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYJpZufMISkc"
   },
   "source": [
    "# Applying OneHotEncoder and converting into 0,1 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Nl62PQb7A6D"
   },
   "outputs": [],
   "source": [
    "# It is an important technique for converting categorical attributes into a numeric vector\n",
    "one_hot = OneHotEncoder(inputCols = [\"newsales\",\"newsalary\"], outputCols = [\"newsales_onehot\",\"newsalary_onehot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6g8T0tq7W8R"
   },
   "outputs": [],
   "source": [
    "# It is feature transformer that combine multiple columns into a single vector column.\n",
    "# Pyspark ml models takes only one independent variable and one dependent varibale\n",
    "#but, we have multiple independent variabales, so we use vector assembler to convert them into a single list\n",
    "# of independent variables\n",
    "vec_ass = VectorAssembler(inputCols = ['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','promotion_last_5years','newsales_onehot','newsalary_onehot'], outputCol = \"all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELc5SnSO8hio"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol= \"all_features\", labelCol = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYBTowpII6KD"
   },
   "source": [
    "## Creating Pipeline\n",
    "Its like deciding the order of steps to be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2nL2QDw8mAt"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "mypipeline = Pipeline(stages = [str_idx, one_hot, vec_ass, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgOzq6cqJG_b"
   },
   "source": [
    "## Splitting the Dataset\n",
    "# As my roll no is DS5B-2121 I will be using split as 0.71 and 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ce4H_pX78pO8"
   },
   "outputs": [],
   "source": [
    "training, test = data.randomSplit([0.71, 0.29])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnBPhNe7JJS6"
   },
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUnkwNVY8u58"
   },
   "outputs": [],
   "source": [
    "lr_model = mypipeline.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAZWhMkJPGq"
   },
   "source": [
    "## Fitting the data to the model \n",
    "to compute patterns using Train data and then these will be applied on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrqzerhD8zE8"
   },
   "outputs": [],
   "source": [
    "result = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkVyjp9GJMcE"
   },
   "source": [
    "## SHowing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_-3z0Mb85pT",
    "outputId": "a6a8ca50-1bb4-47d0-81fb-0a52c3f0ef90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+---------------+----------------+--------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|sales      |salary|newsales|newsalary|newsales_onehot|newsalary_onehot|all_features                                            |rawPrediction                           |probability                             |prediction|\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+---------------+----------------+--------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|0.09              |0.62           |6             |294                 |4                 |0            |1   |0                    |accounting |low   |8.0     |0.0      |(9,[8],[1.0])  |(2,[0],[1.0])   |(18,[0,1,2,3,4,15,16],[0.09,0.62,6.0,294.0,4.0,1.0,1.0])|[-0.906113009228541,0.906113009228541]  |[0.28779589386338533,0.7122041061366147]|1.0       |\n",
      "|0.09              |0.62           |6             |294                 |4                 |0            |1   |0                    |accounting |low   |8.0     |0.0      |(9,[8],[1.0])  |(2,[0],[1.0])   |(18,[0,1,2,3,4,15,16],[0.09,0.62,6.0,294.0,4.0,1.0,1.0])|[-0.906113009228541,0.906113009228541]  |[0.28779589386338533,0.7122041061366147]|1.0       |\n",
      "|0.09              |0.77           |5             |275                 |4                 |0            |1   |0                    |product_mng|medium|4.0     |1.0      |(9,[4],[1.0])  |(2,[1],[1.0])   |(18,[0,1,2,3,4,11,17],[0.09,0.77,5.0,275.0,4.0,1.0,1.0])|[-0.6706336468375675,0.6706336468375675]|[0.3383549711925885,0.6616450288074115] |1.0       |\n",
      "|0.09              |0.77           |6             |244                 |4                 |0            |1   |0                    |product_mng|low   |4.0     |0.0      |(9,[4],[1.0])  |(2,[0],[1.0])   |(18,[0,1,2,3,4,11,16],[0.09,0.77,6.0,244.0,4.0,1.0,1.0])|[-0.7998272517122431,0.7998272517122431]|[0.31006247261884357,0.6899375273811564]|1.0       |\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+---------------+----------------+--------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(4, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyEFrnD7JfFy"
   },
   "source": [
    "## Evaluating the Logistic Regression Model using MultiClassificationEvaluator\n",
    "As the number of unique values the dependent variable could take are more than 2, we have to apply MultiClassificationEvaluator insted of BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1VrpcNq87h8",
    "outputId": "884d2782-cc3d-4272-c2c7-3326895dbef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 : 0.7779568868738669\n",
      "accuracy : 0.801658604008293\n",
      "weightedPrecision : 0.7820065880658045\n",
      "weightedRecall : 0.8016586040082929\n",
      "weightedTruePositiveRate : 0.8016586040082929\n",
      "weightedFalsePositiveRate : 0.5166086426447655\n",
      "weightedFMeasure : 0.7779568868738669\n",
      "truePositiveRateByLabel : 0.9422208847427024\n",
      "falsePositiveRateByLabel : 0.6571709233791748\n",
      "precisionByLabel : 0.8239473684210527\n",
      "recallByLabel : 0.9422208847427024\n",
      "fMeasureByLabel : 0.8791239646216482\n",
      "logLoss : 0.4152158353029982\n",
      "hammingLoss : 0.19834139599170697\n"
     ]
    }
   ],
   "source": [
    "evaluation = [\"f1\",\"accuracy\",\"weightedPrecision\",\"weightedRecall\", \"weightedTruePositiveRate\", \"weightedFalsePositiveRate\", \"weightedFMeasure\", \"truePositiveRateByLabel\", \"falsePositiveRateByLabel\", \"precisionByLabel\",\"recallByLabel\", \"fMeasureByLabel\", \"logLoss\",\"hammingLoss\"]\n",
    "for i in evaluation:\n",
    "  from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "  eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol= \"left\", metricName=i)\n",
    "  print(i, \":\", eval.evaluate(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUNZ0fnhK8Cg"
   },
   "source": [
    "# Building the Decision Tree Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxAo5IJtFnck"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(featuresCol= \"all_features\", labelCol = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HXC9RJeLAyv"
   },
   "source": [
    "## Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYVuAb_DKHxM"
   },
   "outputs": [],
   "source": [
    "dtc_model = mypipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0b3WrzSKOtU"
   },
   "outputs": [],
   "source": [
    "result2 = dtc_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L40ZF14LDo5"
   },
   "source": [
    "## Tranforming Data to compute the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckkE1MiOKqEi",
    "outputId": "eebe1416-5ac0-44dc-de78-7024e2bdcf6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+---------------+----------------+--------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|sales      |salary|newsales|newsalary|newsales_onehot|newsalary_onehot|all_features                                            |rawPrediction                           |probability                             |prediction|\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+---------------+----------------+--------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|0.09              |0.62           |6             |294                 |4                 |0            |1   |0                    |accounting |low   |8.0     |0.0      |(9,[8],[1.0])  |(2,[0],[1.0])   |(18,[0,1,2,3,4,15,16],[0.09,0.62,6.0,294.0,4.0,1.0,1.0])|[-0.906113009228541,0.906113009228541]  |[0.28779589386338533,0.7122041061366147]|1.0       |\n",
      "|0.09              |0.62           |6             |294                 |4                 |0            |1   |0                    |accounting |low   |8.0     |0.0      |(9,[8],[1.0])  |(2,[0],[1.0])   |(18,[0,1,2,3,4,15,16],[0.09,0.62,6.0,294.0,4.0,1.0,1.0])|[-0.906113009228541,0.906113009228541]  |[0.28779589386338533,0.7122041061366147]|1.0       |\n",
      "|0.09              |0.77           |5             |275                 |4                 |0            |1   |0                    |product_mng|medium|4.0     |1.0      |(9,[4],[1.0])  |(2,[1],[1.0])   |(18,[0,1,2,3,4,11,17],[0.09,0.77,5.0,275.0,4.0,1.0,1.0])|[-0.6706336468375675,0.6706336468375675]|[0.3383549711925885,0.6616450288074115] |1.0       |\n",
      "|0.09              |0.77           |6             |244                 |4                 |0            |1   |0                    |product_mng|low   |4.0     |0.0      |(9,[4],[1.0])  |(2,[0],[1.0])   |(18,[0,1,2,3,4,11,16],[0.09,0.77,6.0,244.0,4.0,1.0,1.0])|[-0.7998272517122431,0.7998272517122431]|[0.31006247261884357,0.6899375273811564]|1.0       |\n",
      "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+---------------+----------------+--------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2.show(4, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAbR0BKtLb5n"
   },
   "source": [
    "## Evaluation of Decision Tree Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd8ST-IbKuSq",
    "outputId": "6e1d1078-aa6f-43b5-a4ae-99cb631bd580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 : 0.7779568868738669\n",
      "accuracy : 0.801658604008293\n",
      "weightedPrecision : 0.7820065880658045\n",
      "weightedRecall : 0.8016586040082929\n",
      "weightedTruePositiveRate : 0.8016586040082929\n",
      "weightedFalsePositiveRate : 0.5166086426447655\n",
      "weightedFMeasure : 0.7779568868738669\n",
      "truePositiveRateByLabel : 0.9422208847427024\n",
      "falsePositiveRateByLabel : 0.6571709233791748\n",
      "precisionByLabel : 0.8239473684210527\n",
      "recallByLabel : 0.9422208847427024\n",
      "fMeasureByLabel : 0.8791239646216482\n",
      "logLoss : 0.4152158353029982\n",
      "hammingLoss : 0.19834139599170697\n"
     ]
    }
   ],
   "source": [
    "evaluation = [\"f1\",\"accuracy\",\"weightedPrecision\",\"weightedRecall\", \"weightedTruePositiveRate\", \"weightedFalsePositiveRate\", \"weightedFMeasure\", \"truePositiveRateByLabel\", \"falsePositiveRateByLabel\", \"precisionByLabel\",\"recallByLabel\", \"fMeasureByLabel\", \"logLoss\",\"hammingLoss\"]\n",
    "for i in evaluation:\n",
    "  from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "  eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol= \"left\", metricName=i)\n",
    "  print(i, \":\", eval.evaluate(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYTg-TAwK3ES"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
